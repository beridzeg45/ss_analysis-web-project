{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "! python scrape_article_urls.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! python scrape_article_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge daily DF and all time DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df=pd.read_csv('data/daily_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/all_time_unprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df,daily_df],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates(subset=['Article ID','Date Published'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df) > 50 * 10**3:\n",
    "    df.to_csv('data/all_time_unprocessed.csv', index=False)\n",
    "else:\n",
    "    raise ValueError('DataFrame length is not greater than 50,000. Cannot proceed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#article ID\n",
    "df['Article ID']=df['Article ID'].str.replace('ID|-','',regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date Published and Time Scraped\n",
    "month_dict={\n",
    " 'იან':'January',\n",
    " 'თებ':'February',\n",
    " 'მარ':'March',\n",
    " 'აპრ':'April',\n",
    " 'მაი':'May',\n",
    " 'ივნ':'June',\n",
    " 'ივლ':'July',\n",
    " 'აგვ':'August',\n",
    " 'სექ':'September',\n",
    " 'ოქტ':'October',\n",
    " 'ნოე':'November',\n",
    " 'დეკ':'December'\n",
    "}\n",
    "\n",
    "df['Date Published']=df['Date Published'].replace(month_dict, regex=True)\n",
    "df['Date Published']=pd.to_datetime(df['Date Published'],errors='coerce').dt.date\n",
    "\n",
    "time_scraped=df['Time Scraped'].tolist()\n",
    "df=df.drop(columns='Time Scraped')\n",
    "df.insert(\n",
    "    df.columns.get_loc('Date Published')+1,\n",
    "    'Time Scraped',\n",
    "    time_scraped\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Addresses\n",
    "df.drop('General Address',axis=1,errors='ignore',inplace=True)\n",
    "df.insert(\n",
    "    df.columns.get_loc('Address'),\n",
    "    'General Address',\n",
    "    df['Title'].apply(lambda x:x.split('ბინა ')[-1] if isinstance(x,str) else None)\n",
    ")\n",
    "suburb_dict={\n",
    "    'აეროპორტ': 'აეროპორტის დასახლება',\n",
    "    'ავჭალ': 'ავაჭალა',\n",
    "    'ავლაბარ': 'ავლაბარი',\n",
    "    'აფრიკ': 'აფრიკის დასახლება',\n",
    "    'ბაგებ': 'ბაგები',\n",
    "    'გლდან': 'გლდანი',\n",
    "    'დიდ დიღომ': 'დიდი დიღომი',\n",
    "    'დიდი დიღომ': 'დიდი დიღომი',\n",
    "    'დიდუბ': 'დიდუბე',\n",
    "    'დიღმის მასივ': 'დიღმის მასივი',\n",
    "    'მასივ': 'დიღმის მასივი',\n",
    "    'დიღომი 1': 'დიღომი',\n",
    "    'ვაზისუბ': 'ვაზისუბანი',\n",
    "    'ვაკე': 'ვაკე',\n",
    "    'ვაჟა': 'ვაჟა-ფშაველა',\n",
    "    'ფშაველა': 'ვაჟა-ფშაველა',\n",
    "    'ვარკეთილ': 'ვარკეთილი',\n",
    "    'ვაშლიჯ': 'ვაშლიჯვარი',\n",
    "    'ვერა': 'ვერა',\n",
    "    'ვეძის': 'ვეძისი',\n",
    "    'ზაჰეს': 'ზაჰესი',\n",
    "    'თემქ': 'თემქა',\n",
    "    'ივერთუბ': 'ივერთუბანი',\n",
    "    'ისან': 'ისანი',\n",
    "    'ლილო': 'ლილოს დასახლება',\n",
    "    'ლისის': 'ლისის ტბის დასახლება',\n",
    "    'ლისზე': 'ლისის ტბის დასახლება',\n",
    "    'მთაწმინდ': 'მთაწმინდა',\n",
    "    'მუხიან': 'მუხიანი',\n",
    "    'ნავთლუღ': 'ნავთლუღი',\n",
    "    'ნაძალად': 'ნაძალადევი',\n",
    "    'ნახალოვ': 'ნახალოვკა',\n",
    "    'ნუცუბიძ': 'ნუცუბიძის პლატო',\n",
    "    'ორთაჭალ': 'ორთაჭალა',\n",
    "    'ორხევ': 'ორხევი',\n",
    "    'საბურთალ': 'საბურთალო',\n",
    "    'სამგორ': 'სამგორი',\n",
    "    'სანზონ': 'სანზონა',\n",
    "    'სოლოლაკ': 'სოლოლაკი',\n",
    "    'სოფელ დიღომ': 'სოფელი დიღომი',\n",
    "    'სოფელი დიღომ': 'სოფელი დიღომი',\n",
    "    'სოფ. დიღო': 'სოფელი დიღომი',\n",
    "    'ფონიჭ': 'ფონიჭალა',\n",
    "    'ჩუღურეთ': 'ჩუღურეთი',\n",
    "    'ძველ თბილი': 'ძველი თბილისი',\n",
    "    'ძველი თბილი': 'ძველი თბილისი'\n",
    " }\n",
    "\n",
    "def contains_key(x):\n",
    "    for key, value in suburb_dict.items():\n",
    "        if key in str(x):\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "\n",
    "#make more general\n",
    "df['General Address'] = df['General Address'].apply(contains_key)\n",
    "\n",
    "df.drop('Detailed Address',axis=1,errors='ignore',inplace=True)\n",
    "df.insert(\n",
    "    df.columns.get_loc('Address'),\n",
    "    'Detailed Address',\n",
    "    df['Address'].apply(lambda x:x.split(', ')[-1] if isinstance(x,str) else None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['address_simplified']=df['Address'].apply(lambda x:\n",
    "                    'თბილისი,'+x.split('ქ.')[0].split('გამზ')[0].replace(' 0','').replace(' 1','').replace(' 2','').replace(' 3','').split(',')[-1] if isinstance(x,str) else None\n",
    "                    )\n",
    "\n",
    "\n",
    "coordinates_dict=pickle.load(open(\"data/coordinates_dict.pickle\",'rb'))\n",
    "\n",
    "def map_coordinates(address):\n",
    "    if address in coordinates_dict:\n",
    "        return coordinates_dict[address]\n",
    "    else:\n",
    "        return {'Lat': None, 'Lon': None, 'Street': None}\n",
    "    \n",
    "mapped_coordinates=df['address_simplified'].apply(map_coordinates)\n",
    "mapped_df=pd.DataFrame(mapped_coordinates.tolist(),index=df.index)\n",
    "df=pd.concat([df,mapped_df],axis=1)\n",
    "\n",
    "df=df.drop(columns='address_simplified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ast_(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['Details_1']=df['Details_1'].apply(lambda x:ast_(x))\n",
    "df['Details_2']=df['Details_2'].apply(lambda x:ast_(x))\n",
    "\n",
    "\n",
    "df['Area SQMT'] = [str(i['საერთო ფართი']).split(' ')[0] if i and i.get('საერთო ფართი') else None for i in df['Details_1']]\n",
    "df['Area SQMT']=pd.to_numeric(df['Area SQMT'],errors='coerce')\n",
    "\n",
    "df['Rooms'] = [i['ოთახი'] if i and i.get('ოთახი') else None for i in df['Details_1']]\n",
    "df['Rooms']=pd.to_numeric(df['Rooms'],errors='coerce')\n",
    "\n",
    "df['Bedrooms'] = [float(i['საძინებელი']) if i and i.get('საძინებელი') else None for i in df['Details_1']]\n",
    "df['Bedrooms']=pd.to_numeric(df['Bedrooms'],errors='coerce')\n",
    "\n",
    "df['Floor'] = [i['სართული'].split('/')[0] if i and i.get('სართული') else None for i in df['Details_1']]\n",
    "df['Floor']=pd.to_numeric(df['Floor'],errors='coerce')\n",
    "\n",
    "df['Max Floors'] = [i['სართული'].split('/')[-1] if i and i.get('სართული') else None for i in df['Details_1']]\n",
    "df['Max Floors']=pd.to_numeric(df['Max Floors'],errors='coerce')\n",
    "\n",
    "df['Condition'] = [i['მდგომარეობა'] if i and i.get('მდგომარეობა') else None for i in df['Details_2']]\n",
    "\n",
    "df['Project'] = [i['პროექტი'] if i and i.get('პროექტი') else None for i in df['Details_2']]\n",
    "\n",
    "df['Bathrooms'] = [i['სველი წერტილი'] if i and i.get('სველი წერტილი') else None for i in df['Details_2']]\n",
    "df['Bathrooms']=pd.to_numeric(df['Bathrooms'],errors='coerce')\n",
    "\n",
    "df['Status'] = [i['სტატუსი'] if i and i.get('სტატუსი') else None for i in df['Details_2']]\n",
    "\n",
    "\n",
    "df=df.drop(columns=['Details_1','Details_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Price\n",
    "\"\"\"df['Price USD']=df.apply(lambda x:\n",
    "                  float(x['Price'].split('$')[0].replace(',','')) if '$' in str(x) else \n",
    "                  float(x['Price'].split('₾')[0].replace(',',''))/x['USD-GEL Rate'] if '₾' in str(x) else None, axis=1\n",
    "                  )\"\"\"\n",
    "\n",
    "df['Price USD']=df['Price'].str.split('$').str[0].str.replace(',','').apply(pd.to_numeric,errors='coerce')\n",
    "\n",
    "df=df.drop(columns='Price')\n",
    "\n",
    "df=df[(df['Price USD']>0)&(df['Area SQMT']>0)]\n",
    "df['Price Per SQMT']=(df['Price USD']/df['Area SQMT']).round(2)\n",
    "df=df.dropna(subset=['Price Per SQMT'])\n",
    "\n",
    "mean_price=df['Price Per SQMT'].mean()\n",
    "std_price=df['Price Per SQMT'].mean()\n",
    "df=df.query('@mean_price-5*@std_price<`Price Per SQMT`<@mean_price+5*@std_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.replace('{',None).replace('}',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing\n"
     ]
    }
   ],
   "source": [
    "#save the processed df\n",
    "\n",
    "processed_df=df\n",
    "processed_df.to_csv('data/all_time_processed.csv',index=False)\n",
    "print('Finished preprocessing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouped DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['Date Published']=pd.to_datetime(df['Date Published'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished all_time_grouped.csv\n"
     ]
    }
   ],
   "source": [
    "all_time_grouped=processed_df.groupby([processed_df['Date Published'].dt.date,'General Address','Status','Condition']).agg({'Article ID':'count','Price Per SQMT':'median'}).reset_index()\n",
    "\n",
    "all_time_grouped=all_time_grouped.sort_values('Date Published')\n",
    "\n",
    "#all_time_grouped.to_csv(os.path.join('dash','all_time_grouped.csv'),index=False)\n",
    "all_time_grouped.to_csv(os.path.join('data','all_time_grouped.csv'),index=False)\n",
    "\n",
    "print('Finished all_time_grouped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-23 00:00:00 2023-11-27 00:00:00\n"
     ]
    }
   ],
   "source": [
    "min_date=pd.to_datetime(all_time_grouped['Date Published']).min()\n",
    "max_date=pd.to_datetime(all_time_grouped['Date Published']).max()\n",
    "\n",
    "print(min_date, max_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordinates DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_df=processed_df[['Date Published','Price Per SQMT','Lat','Lon','Street']]\n",
    "coordinates_df['Size']=coordinates_df.index\n",
    "\n",
    "coordinates_grouped=coordinates_df.groupby([coordinates_df['Date Published'].dt.to_period('W'),'Lat','Lon','Street']).agg({'Size':'count','Price Per SQMT':'median'}).reset_index()\n",
    "coordinates_grouped['Price Per SQMT']=coordinates_grouped['Price Per SQMT']/coordinates_grouped['Price Per SQMT'].sum()\n",
    "\n",
    "coordinates_grouped.to_csv('data/coordinates_grouped.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
